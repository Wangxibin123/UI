import OpenAI from 'openai';

// ğŸ¯ AIæ¨¡å‹ç±»å‹å®šä¹‰
export type AIProvider = 'openrouter' | 'openai' | 'anthropic' | 'deepseek';

export interface AIModel {
  id: string;
  name: string;
  provider: AIProvider;
  openrouterModelId?: string; // OpenRouteræ¨¡å‹ID
  supportsImages: boolean;
  maxTokens?: number;
  description?: string;
}

export interface ChatMessage {
  role: 'user' | 'assistant' | 'system';
  content: string | Array<{
    type: 'text' | 'image_url';
    text?: string;
    image_url?: {
      url: string;
    };
  }>;
}

export interface ChatCompletionOptions {
  model: string;
  messages: ChatMessage[];
  maxTokens?: number;
  temperature?: number;
  stream?: boolean;
}

// ğŸ¯ æ”¯æŒçš„AIæ¨¡å‹é…ç½®
export const AI_MODELS: AIModel[] = [
  // DeepSeek ç³»åˆ—
  {
    id: 'deepseek-chat-v3',
    name: 'DeepSeek Chat V3',
    provider: 'openrouter',
    openrouterModelId: 'deepseek/deepseek-chat-v3-0324',
    supportsImages: false,
    description: 'æ·±åº¦æ€è€ƒå¯¹è¯æ¨¡å‹'
  },
  {
    id: 'deepseek-r1',
    name: 'DeepSeek R1',
    provider: 'openrouter',
    openrouterModelId: 'deepseek/deepseek-r1',
    supportsImages: false,
    description: 'æ¨ç†ä¸“ç”¨æ¨¡å‹'
  },
  {
    id: 'deepseek-prover-v2',
    name: 'DeepSeek Prover V2',
    provider: 'openrouter',
    openrouterModelId: 'deepseek/deepseek-prover-v2',
    supportsImages: false,
    description: 'æ•°å­¦è¯æ˜ä¸“ç”¨æ¨¡å‹'
  },
  
  // OpenAI ç³»åˆ—
  {
    id: 'gpt-4.1',
    name: 'GPT-4.1',
    provider: 'openrouter',
    openrouterModelId: 'openai/gpt-4.1',
    supportsImages: true,
    description: 'OpenAIæœ€æ–°æ——èˆ°æ¨¡å‹'
  },
  {
    id: 'gpt-4.5-preview',
    name: 'GPT-4.5 Preview',
    provider: 'openrouter',
    openrouterModelId: 'openai/gpt-4.5-preview',
    supportsImages: true,
    description: 'GPT-4.5é¢„è§ˆç‰ˆ'
  },
  {
    id: 'o3',
    name: 'OpenAI O3',
    provider: 'openai',
    supportsImages: true,
    description: 'OpenAI O3æ¨ç†æ¨¡å‹'
  },
  
  // Anthropic Claude ç³»åˆ—
  {
    id: 'claude-opus-4',
    name: 'Claude Opus 4',
    provider: 'openrouter',
    openrouterModelId: 'anthropic/claude-opus-4',
    supportsImages: true,
    description: 'Claudeæœ€å¼ºæ¨¡å‹'
  },
  {
    id: 'claude-sonnet-4',
    name: 'Claude Sonnet 4',
    provider: 'openrouter',
    openrouterModelId: 'anthropic/claude-sonnet-4',
    supportsImages: true,
    description: 'Claudeå¹³è¡¡æ¨¡å‹'
  },
  {
    id: 'claude-3.7-sonnet-thinking',
    name: 'Claude 3.7 Sonnet (Thinking)',
    provider: 'openrouter',
    openrouterModelId: 'anthropic/claude-3.7-sonnet:thinking',
    supportsImages: true,
    description: 'Claudeæ€ç»´æ¨¡å¼'
  },
  
  // Google Gemini ç³»åˆ—
  {
    id: 'gemini-2.5-flash-preview',
    name: 'Gemini 2.5 Flash Preview',
    provider: 'openrouter',
    openrouterModelId: 'google/gemini-2.5-flash-preview-05-20',
    supportsImages: true,
    description: 'Googleæœ€æ–°è§†è§‰æ¨¡å‹'
  },
  {
    id: 'gemini-2.5-flash-thinking',
    name: 'Gemini 2.5 Flash (Thinking)',
    provider: 'openrouter',
    openrouterModelId: 'google/gemini-2.5-flash-preview-05-20:thinking',
    supportsImages: true,
    description: 'Geminiæ€ç»´æ¨¡å¼'
  },
  
  // Qwen ç³»åˆ—
  {
    id: 'qwen2.5-vl-32b',
    name: 'Qwen 2.5 VL 32B',
    provider: 'openrouter',
    openrouterModelId: 'qwen/qwen2.5-vl-32b-instruct',
    supportsImages: true,
    description: 'é€šä¹‰åƒé—®è§†è§‰æ¨¡å‹'
  },
  {
    id: 'qwen2.5-vl-72b',
    name: 'Qwen 2.5 VL 72B',
    provider: 'openrouter',
    openrouterModelId: 'qwen/qwen2.5-vl-72b-instruct',
    supportsImages: true,
    description: 'é€šä¹‰åƒé—®å¤§å‹è§†è§‰æ¨¡å‹'
  },
  {
    id: 'qwen3-235b',
    name: 'Qwen 3 235B',
    provider: 'openrouter',
    openrouterModelId: 'qwen/qwen3-235b-a22b',
    supportsImages: false,
    description: 'é€šä¹‰åƒé—®è¶…å¤§æ¨¡å‹'
  },
  {
    id: 'qwen3-32b',
    name: 'Qwen 3 32B',
    provider: 'openrouter',
    openrouterModelId: 'qwen/qwen3-32b',
    supportsImages: false,
    description: 'é€šä¹‰åƒé—®é«˜æ•ˆæ¨¡å‹'
  }
];

// ğŸ¯ AIæ¨¡å‹æœåŠ¡ç±»
export class AIModelService {
  private openrouterClient: OpenAI;
  private openaiClient: OpenAI | null = null;
  private siteUrl: string;
  private siteName: string;

  constructor() {
    // è·å–ç¯å¢ƒå˜é‡
    const openrouterApiKey = import.meta.env.VITE_OPENROUTER_API_KEY;
    const openaiApiKey = import.meta.env.VITE_OPENAI_API_KEY;
    this.siteUrl = import.meta.env.VITE_SITE_URL || 'http://localhost:5173';
    this.siteName = import.meta.env.VITE_SITE_NAME || 'AIè§£é¢˜åŠ©æ‰‹';

    // åˆå§‹åŒ–OpenRouterå®¢æˆ·ç«¯
    if (!openrouterApiKey) {
      console.warn('OpenRouter API Key æœªè®¾ç½®');
    }
    
    this.openrouterClient = new OpenAI({
      baseURL: "https://openrouter.ai/api/v1",
      apiKey: openrouterApiKey || '',
      defaultHeaders: {
        "HTTP-Referer": this.siteUrl,
        "X-Title": this.siteName,
      },
      dangerouslyAllowBrowser: true
    });

    // åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯ï¼ˆç”¨äºO3æ¨¡å‹ï¼‰
    if (openaiApiKey) {
      this.openaiClient = new OpenAI({
        apiKey: openaiApiKey,
        dangerouslyAllowBrowser: true
      });
    }
  }

  // ğŸ¯ è·å–æ‰€æœ‰å¯ç”¨æ¨¡å‹
  getAvailableModels(): AIModel[] {
    return AI_MODELS;
  }

  // ğŸ¯ æ ¹æ®IDè·å–æ¨¡å‹ä¿¡æ¯
  getModelById(modelId: string): AIModel | undefined {
    return AI_MODELS.find(model => model.id === modelId);
  }

  // ğŸ¯ æŒ‰æä¾›å•†åˆ†ç»„æ¨¡å‹
  getModelsByProvider(): Record<AIProvider, AIModel[]> {
    const grouped: Record<AIProvider, AIModel[]> = {
      openrouter: [],
      openai: [],
      anthropic: [],
      deepseek: []
    };

    AI_MODELS.forEach(model => {
      grouped[model.provider].push(model);
    });

    return grouped;
  }

  // ğŸ¯ è°ƒç”¨AIæ¨¡å‹è¿›è¡Œå¯¹è¯
  async chatCompletion(options: ChatCompletionOptions): Promise<string> {
    const model = this.getModelById(options.model);
    if (!model) {
      throw new Error(`æœªæ‰¾åˆ°æ¨¡å‹: ${options.model}`);
    }

    try {
      switch (model.provider) {
        case 'openrouter':
          return await this.callOpenRouterModel(model, options);
        
        case 'openai':
          return await this.callOpenAIModel(model, options);
        
        default:
          throw new Error(`ä¸æ”¯æŒçš„æä¾›å•†: ${model.provider}`);
      }
    } catch (error) {
      console.error('AIæ¨¡å‹è°ƒç”¨å¤±è´¥:', error);
      throw error;
    }
  }

  // ğŸ¯ è°ƒç”¨OpenRouteræ¨¡å‹
  private async callOpenRouterModel(model: AIModel, options: ChatCompletionOptions): Promise<string> {
    const completion = await this.openrouterClient.chat.completions.create({
      model: model.openrouterModelId!,
      messages: options.messages as any,
      max_tokens: options.maxTokens,
      temperature: options.temperature || 0.7,
      stream: false
    });

    return completion.choices[0]?.message?.content || '';
  }

  // ğŸ¯ è°ƒç”¨OpenAI O3æ¨¡å‹ï¼ˆä½¿ç”¨æ–°çš„responses APIï¼‰
  private async callOpenAIModel(model: AIModel, options: ChatCompletionOptions): Promise<string> {
    if (!this.openaiClient) {
      throw new Error('OpenAI API Key æœªè®¾ç½®');
    }

    if (model.id === 'o3') {
      // ä½¿ç”¨æ–°çš„responses APIè°ƒç”¨O3
      const response = await (this.openaiClient as any).responses.create({
        model: "o3",
        input: options.messages.map(msg => ({
          role: msg.role,
          content: msg.content
        }))
      });
      
      return response.output_text || '';
    } else {
      // ä½¿ç”¨æ ‡å‡†çš„chat completions API
      const completion = await this.openaiClient.chat.completions.create({
        model: model.openrouterModelId || model.id,
        messages: options.messages as any,
        max_tokens: options.maxTokens,
        temperature: options.temperature || 0.7
      });

      return completion.choices[0]?.message?.content || '';
    }
  }

  // ğŸ¯ æµå¼è°ƒç”¨ï¼ˆç”¨äºå®æ—¶å¯¹è¯ï¼‰
  async streamChatCompletion(
    options: ChatCompletionOptions, 
    onChunk: (chunk: string) => void
  ): Promise<void> {
    const model = this.getModelById(options.model);
    if (!model) {
      throw new Error(`æœªæ‰¾åˆ°æ¨¡å‹: ${options.model}`);
    }

    if (model.provider === 'openrouter') {
      const stream = await this.openrouterClient.chat.completions.create({
        model: model.openrouterModelId!,
        messages: options.messages as any,
        max_tokens: options.maxTokens,
        temperature: options.temperature || 0.7,
        stream: true
      });

      for await (const chunk of stream) {
        const content = chunk.choices[0]?.delta?.content;
        if (content) {
          onChunk(content);
        }
      }
    } else if (model.provider === 'openai' && model.id === 'o3') {
      if (!this.openaiClient) {
        throw new Error('OpenAI API Key æœªè®¾ç½®');
      }

      // O3æµå¼è°ƒç”¨
      const stream = await (this.openaiClient as any).responses.create({
        model: "o3",
        input: options.messages.map(msg => ({
          role: msg.role,
          content: msg.content
        })),
        stream: true
      });

      for await (const event of stream) {
        if (event.output_text) {
          onChunk(event.output_text);
        }
      }
    }
  }

  // ğŸ¯ æ£€æŸ¥æ¨¡å‹å¯ç”¨æ€§
  isModelAvailable(modelId: string): boolean {
    const model = this.getModelById(modelId);
    if (!model) return false;

    switch (model.provider) {
      case 'openrouter':
        return !!import.meta.env.VITE_OPENROUTER_API_KEY;
      case 'openai':
        return !!import.meta.env.VITE_OPENAI_API_KEY;
      case 'anthropic':
        return !!import.meta.env.VITE_CLAUDE_API_KEY;
      case 'deepseek':
        return !!import.meta.env.VITE_DEEPSEEK_API_KEY;
      default:
        return false;
    }
  }

  // ğŸ¯ è·å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨
  getAvailableModelIds(): string[] {
    return AI_MODELS
      .filter(model => this.isModelAvailable(model.id))
      .map(model => model.id);
  }
}

// ğŸ¯ å¯¼å‡ºå•ä¾‹å®ä¾‹
export const aiModelService = new AIModelService(); 